#!/bin/bash
# 02614 - High-Performance Computing, January 2022
# 
# batch script to run matmult on a decidated server in the hpcintro
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#
#BSUB -J mm_batch_gpu
#BSUB -o mm_batch_gpu%J.out
#BSUB -q hpcintrogpu
#BSUB -n 1
#BSUB -R "rusage[mem=4096]"
### -- Select the resources: for jobs using 2 GPUs use num=2
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 1:00
#BSUB -R "select[model == XeonE5_2660v3]"
# uncomment the following line, if you want to assure that your job has
# a whole CPU for itself (shared L3 cache)
#BSUB -R "span[hosts=1] affinity[socket(1)]"

# Load the cuda module
module load cuda/11.5.1
module load gcc/10.3.0-binutils-2.36.1

# define the driver name to use
# valid values: matmult_c.studio, matmult_f.studio, matmult_c.gcc or
# matmult_f.gcc
#
EXECUTABLE=matmult_f.nvcc

# define the mkn values in the MKN variable
#
SIZES="100 196 384 753 1476 2893 5669 11112 21780 42688"

# define the permutation type in PERM
#
PERM="mkn"

# uncomment and set a reasonable BLKSIZE for the blk version
#
# BLKSIZE=1

# enable(1)/disable(0) result checking
export MATMULT_COMPARE=0    # - control result comparison (def: 1)
# export MATMULT_RESULTS={[0]|1}	# - print result matrices (in Matlab format, def: 0)
# export MFLOPS_MIN_T=[3.0]        # - the minimum run-time (def: 3.0 s)
export MFLOPS_MAX_IT=1 # - max. no of iterations; set if you want to do profiling.
export MKL_NUM_THREADS=1 # For running on one core on CPU


# start the collect command with the above settings
for S in $SIZES
do
    ./$EXECUTABLE $PERM $S $S $S $BLKSIZE
done
