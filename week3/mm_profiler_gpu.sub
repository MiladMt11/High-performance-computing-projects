#!/bin/bash
# 02614 - High-Performance Computing, January 2022
# 
# batch script to run matmult on a decidated server in the hpcintro
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#
#BSUB -J mm_profiler
#BSUB -o mm_profiler_%J.out
#BSUB -q hpcintrogpu
#BSUB -n 1
#BSUB -R "rusage[mem=2048]"
### -- Select the resources: for jobs using 2 GPUs use num=2
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 10
#BSUB -R "select[model == XeonE5_2660v3]"
# uncomment the following line, if you want to assure that your job has
# a whole CPU for itself (shared L3 cache)
#BSUB -R "span[hosts=1] affinity[socket(1)]"

export TMPDIR=$__LSF_JOB_TMPDIR__ 

# Load the cuda module
module load cuda/11.5.1
module load gcc/10.3.0-binutils-2.36.1

export MFLOPS_MAX_IT=1  

nv-nsight-cu-cli -o profile_$LSB_JOBID \ 
    --section MemoryWorkloadAnalysis \ 
    --section MemoryWorkloadAnalysis_Chart \ 
    --section ComputeWorkloadAnalysis \ 


EXECUTABLE=matmult_f.nvcc

# define the mkn values in the MKN variable
#
SIZES="2048 2048 2048"

# define the permutation type in PERM
#
PERM="gpu2"


# start the collect command with the above settings
for S in $SIZES
do
    ./$EXECUTABLE $PERM $S $S $S 
done
