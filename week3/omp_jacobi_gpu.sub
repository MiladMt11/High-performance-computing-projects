#!/bin/bash
# 02614 - High-Performance Computing, January 2022
# 
# batch script to run collect on a decidated server in the hpcintro
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#
# Note: to get more cores, change the n value below to the
#       number of cores you want to use.  Later on, use the
#       $LSB_DJOB_NUMPROC variable to use this number, e.g. in
#       export OMP_NUM_THREADS=$LSB_DJOB_NUMPROC
#
#BSUB -o mm_batch_%J.out
#BSUB -R "rusage[mem=2GB]"
#BSUB -J jacobi_gpu
#BSUB -q hpcintrogpu
### -- Select the resources: for jobs using 2 GPUs use num=2
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 30
#BSUB -R "select[model == XeonE5_2660v3]"
#BSUB -n 16 -R "span[hosts=1]"

# Load the cuda module
module load cuda/11.5.1
module load gcc/10.3.0-binutils-2.36.1

# define the executable here
#
EXECUTABLE=poisson_j

# define any command line options for your executable here
EXECOPTS="100 10000 .0001 200"

# set some OpenMP variables here
#
# no. of threads
export OMP_NUM_THREADS=$LSB_DJOB_NUMPROC
#
# keep idle threads spinning (needed to monitor idle times!)
export OMP_WAIT_POLICY=active
#
# if you use a runtime schedule, define it below
export OMP_SCHEDULE=dynamic,50
export OMP_DISPLAY_ENV=verbose

# check these?
# export OMP_PLACES=numa_domains
# export $VAR=spread
# export OMP_DISPLAY_AFFINITY=verbose

# experiment name 
#
JID=${LSB_JOBID}
EXPOUT="$LSB_JOBNAME.${JID}.er"

# start the collect command with the above settings
lscpu
collect -o $EXPOUT ./$EXECUTABLE $EXECOPTS
time ./$EXECUTABLE $EXECOPTS

# TODO: discuss
# for MPI: two nodes, using 4 cores/node
# #!/bin/bash
# #BSUB -J mpi_para
# #BSUB -o mpi_para_%J.out
# #BSUB -q hpcintro
# #BSUB -W 2 -R "rusage[mem=512MB]"
# #BSUB -n 8 -R "span[ptile=4]"
# module load mpi
# mpirun ...
