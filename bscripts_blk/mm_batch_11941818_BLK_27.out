Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                20
On-line CPU(s) list:   0-19
Thread(s) per core:    1
Core(s) per socket:    10
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 63
Model name:            Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz
Stepping:              2
CPU MHz:               2899.926
CPU max MHz:           3300.0000
CPU min MHz:           1200.0000
BogoMIPS:              5187.67
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              25600K
NUMA node0 CPU(s):     0-9
NUMA node1 CPU(s):     10-19
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d
   234.375   2240.362 # matmult_blk 27
   283.594   2368.518 # matmult_blk 27
   343.148   2300.939 # matmult_blk 27
   414.586   2195.367 # matmult_blk 27
   499.594   2224.759 # matmult_blk 27
   607.523   2238.641 # matmult_blk 27
   734.273   2234.002 # matmult_blk 27
   891.211   2222.771 # matmult_blk 27
  1073.344   2276.082 # matmult_blk 27
  1305.375   2246.635 # matmult_blk 27
  1572.211   2283.331 # matmult_blk 27
  1903.711   2289.459 # matmult_blk 27
  2310.844   2292.396 # matmult_blk 27
  2789.648   2283.107 # matmult_blk 27
  3384.375   2216.798 # matmult_blk 27
  4095.094   2254.935 # matmult_blk 27
  4937.836   2174.511 # matmult_blk 27
  5977.148   2297.223 # matmult_blk 27
  7245.375   2133.409 # matmult_blk 27
  8778.375   2119.550 # matmult_blk 27
 10615.523   2045.477 # matmult_blk 27
 12834.375   2104.346 # matmult_blk 27
 15529.594   2104.803 # matmult_blk 27
 18774.023   2068.551 # matmult_blk 27
 22739.648   2046.154 # matmult_blk 27
 27489.586   2023.537 # matmult_blk 27
 33301.500   2042.516 # matmult_blk 27
 40282.523   2052.104 # matmult_blk 27
 48735.094   2107.547 # matmult_blk 27
 58954.594   2105.600 # matmult_blk 27
 71367.773   2039.499 # matmult_blk 27
 86310.023   2071.064 # matmult_blk 27
104445.023   2041.973 # matmult_blk 27
126476.461   2031.532 # matmult_blk 27
153000.586   2263.749 # matmult_blk 27
185064.844   2103.309 # matmult_blk 27
223928.461   2057.689 # matmult_blk 27
270937.500   2042.588 # matmult_blk 27
327834.375   2088.107 # matmult_blk 27
396679.594   2103.017 # matmult_blk 27
480109.594   2114.735 # matmult_blk 27
581025.961   2038.950 # matmult_blk 27
702810.375   2094.560 # matmult_blk 27
850513.500   2031.296 # matmult_blk 27
1028997.094   2092.359 # matmult_blk 27
1245223.148   2006.686 # matmult_blk 27
1506757.594   2064.544 # matmult_blk 27
1823259.375   2024.934 # matmult_blk 27
2206143.844   1975.990 # matmult_blk 27
2669334.000   1749.427 # matmult_blk 27

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11941818: <mm_batch> in cluster <dcc> Done

Job <mm_batch> was submitted from host <n-62-27-18> by user <s212571> in cluster <dcc> at Wed Jan  5 16:23:09 2022
Job was executed on host(s) <n-62-28-31>, in queue <hpc>, as user <s212571> in cluster <dcc> at Wed Jan  5 16:23:10 2022
</zhome/6d/6/164418> was used as the home directory.
</zhome/6d/6/164418/hpc/week1/assign/bscripts_blk> was used as the working directory.
Started at Wed Jan  5 16:23:10 2022
Terminated at Wed Jan  5 17:48:09 2022
Results reported at Wed Jan  5 17:48:09 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# 02614 - High-Performance Computing, January 2022
# 
# batch script to run matmult on a decidated server in the hpcintro
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#
#BSUB -J mm_batch
#BSUB -o mm_batch_%J_BLK_27.out
#BSUB -e mm_batch_%J_BLK_27.err
#BSUB -q hpc
#BSUB -n 1
#BSUB -R "rusage[mem=4096]"
#BSUB -W 4:00
#BSUB -R "select[model == XeonE5_2660v3]"
# uncomment the following line, if you want to assure that your job has
# a whole CPU for itself (shared L3 cache)
# #BSUB -R "span[hosts=1] affinity[socket(1)]"

# define the driver name to use
# valid values: matmult_c.studio, matmult_f.studio, matmult_c.gcc or
# matmult_f.gcc
#
EXECUTABLE=matmult_c.gcc

# define the mkn values in the MKN variable
#
SIZES="100 110 121 133 146 161 177 195 214 236 259 285 314 345 380 418 459 505 556 612 673 740 814 895 985 1083 1192 1311 1442 1586 1745 1919 2111 2323 2555 2810 3091 3400 3740 4114 4526 4979 5476 6024 6626 7289 8018 8820 9702 10672"

PERM="blk"

# uncomment and set a reasonable BLKSIZE for the blk version
#
BLKSIZE=27

# enable(1)/disable(0) result checking
export MATMULT_COMPARE=0
# export MATMULT_RESULTS={[0]|1}
# export MFLOPS_MIN_T=[3.0]
# export MFLOPS_MAX_IT=[infinity]

cd ..
lscpu
# start the collect command with the above settings
for S in $SIZES
do
    ./$EXECUTABLE $PERM $S $S $S $BLKSIZE
done

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5093.44 sec.
    Max Memory :                                 2611 MB
    Average Memory :                             1740.39 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               1485.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   5099 sec.
    Turnaround time :                            5100 sec.

The output (if any) is above this job summary.



PS:

Read file <mm_batch_11941818_BLK_27.err> for stderr output of this job.

